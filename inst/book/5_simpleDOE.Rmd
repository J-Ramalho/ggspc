
```{r echo=FALSE, message=FALSE, warning=FALSE}
source(here::here("inst/book/setup.R"))
```

# Design of Experiments {#DOE}

Companies manufacturing goods in industrial quantities have a permanent need to improve the features of their products. This is visible in any such industry be it car parts, watches, electronic components for cell phones, chocolates, clothing, medical devices, medicine, ... the list could go on forever. As consumers we expect flawless quality at affordable price and we want to remain free to choose another brand if our confidence has been damaged due to a defective product. Adding to this fortunately the last decades have seen an increasing pressure to develop sustainable products that are responsibly sourced, meet stringent regulations and can last for many years and be properly disposable. Another constraint that can be observed in Research and Development is the growing awareness of the public on ethical issues. There is an increasing expectation that trials generate minimal waste and are done in a way respectful of test subjects human and animal.

Experiment design provides ways to meet these important requirements by making us think upfront on what is required and how to best approach a test. Integrated in a complete solid design for quality approach it can provide deep insights on the principles of a system and support decision making based on data. A well prepared test plan minimizes trial and error and reduces the number of prototypes, measurements and time required. 

There are many well tested approaches, the domain is very large and our textbook can only cover a subset of the many types of DoEs used in the industry. For all these cases statistical notions are key to have a minimal preparation of the test and a valid interpretation of the results. Some statistical concepts every engineer, technician or scientist has to understand go around sampling, sample size, probability, correlation and variability. It is important to be clear about the vocabulary and the mathematics that are behind the constantly used statistics such as the mean, median, variance, standard deviation and so on. We provide a glossary and good bibliography that can be both a good starting point or a refresher. In particular the text and the case studies follow what we consider to be the most important book in this the domain, the *Design and Analysis of Experiments* by @Montgomery2012.

## Means comparison

<div class="marginnote">

<b class="highlight">Winter Sports clothing manufacture</b>

All winter sports clothing are virtually made with a mix of natural fibers and synthetic polymers. Upgrading to recyclable polymers while keeping performance requires extensive testing of raw material characteristics such as the tensile strength.

```{r echo=FALSE, out.width="100%", fig.align='center', fig.cap="PET tensile test"}
knitr::include_graphics("img/tensile_test_bw.jpg")
```

</div>

We start by exploring simple tests that compare results obtained in two samples. These cases happen all the time as everyone needs one moment or another to compare the behavior of a product in different conditions. It can be the result of a test before and after an improvement, it can be two different materials applied in the same assembly or still different results obtained by different teams at different moments. 

In this case, an engineer working in the <b class="highlight">winter sports clothing industry</b> has established a contract for PET textile raw material supply specifying that the average tensile strength has to be greater than 69.0 $Mpa$ in each delivery. In the contract is also specified that the test protocol which is based on a 30 samples.

A first delivery is submitted and the incoming materials test laboratory measures 28 samples and issues a bulletin with the statement "refused". In small font is written batch mean = 67.7 [MPa]. The batch is returned to the supplier by an automatic workflow established by the Supply Chain department without the Engineer being informed and a few weeks later he gets an e-mail for the supplier key account manager asking for explanations. According to their tests the mean tensile strength of their delivery was slightly above target and they don't understand the reasons for the return. The Quality Engineer logs into his company ERP and with a bit of effort manages to obtain the raw data which he loads in R:

```{r}
summary(pet_delivery$A)
```

The mean is in fact lower that the specified contract value of 69 and the engineer could think to confirm the rejection the batch right away. She decides nevertheless to observe the variability and for this she decides to plot the raw data on an histogram. An histogram is a very common plot showing counts for selected intervals.

### Histogram {#histogram}

```{r fig-pethistogram, fig.cap="histogram example"}
pet_spec <- 69
pet_mean <- mean(pet_delivery$A)
pet_delivery %>% 
  ggplot(aes(x = A)) +
  geom_histogram(color = viridis(12)[4], fill = "grey90") +
  scale_x_continuous(n.breaks = 10) +
  geom_vline(xintercept = pet_mean, color = "darkblue", linetype = 2, size = 1) +
  geom_vline(xintercept = pet_spec, color = "darkred", linetype = 2, 
             show.legend = TRUE) +
  labs(title = "PET raw material delivery",
       subtitle = "Histogram of resistance measurements",
       y = "Count",
       x = "Tensile strength [MPa]", 
       caption = "Specification min in red, Batch mean in blueÂ¨")
```

The mean is just slightly below the target mean defined for acceptance and she also observes a certain variability in the batch. She decides then to perform a t-test to assess if the average calculated can be really be considered statistically different than the target value.

### t-test one sample {#t.test}

```{r}
t.test(x = pet_delivery$A, mu = pet_spec)
```

The basic assumption of the test is that the mean and the reference value are identical and the alternative hypothesis is that their different. The confidence interval selected is 95% as it is common practice in the laboratory. The test result tells us that for a population average of 69, the probability of obtaining a sample with a value as extreme as 68.71 is 29.17% (p = 0.2917). This probability value higher than the limit of 5% that she usually uses to reject the null hypothesis. In fact she cannot conclude that the sample comes from a population with a mean different than 69.

She's not sure of this result and decides asking help to a colleague statistician from R&D: can she apply a t.test? is the sample normally distributed? is the specification correctly defined? or should it refer to the minimum sample value?

### t-test two samples

Comparing means

In order to avoid similar situations in the future the development engineer considers a new chemical compositions of pet that potentially increases the levels of strenght.

**Data loading**

```{r}
pet_delivery_long <- pet_delivery %>%
  pivot_longer(
    cols = everything(), names_to = "sample", values_to = "tensile_strength"
  )
```

**Raw data plot**

In data analysis it is good practice to start by plotting the raw data and have a first open look at what the first plots tell us.

```{r}
pet_delivery_long %>% 
  ggplot(aes(x = sample, y = tensile_strength)) +
  geom_point() +
  theme(legend.position = "none") +
  labs(title = "PET clothing case study",
       subtitle = "Raw data plot",
       x = "Sample",
       y = "Tensile strength [MPa]")
```

Another way to better understanding the bond distributions is to plot a box plot. This type of plot is somehow like the histogram seen before but more compact when several groups are required to be plotted.

```{r}
pet_delivery_long %>% 
  ggplot(aes(x = sample, y = tensile_strength, fill = sample)) +
  geom_boxplot(width = 0.3) +
  scale_fill_viridis_d(begin = 0.5, end = 0.8) +
  theme(legend.position = "none") +
  labs(title = "PET clothing case study",
       subtitle = "Box plot",
       x = "Sample",
       y = "Tensile strength [MPa]")
```

We would like to understand if the treatment has an effect. Thus we want to compare the two population means. For that we use a t test using samples obtained independently and randomly. Before running the test we also have to check the normality of the samples distributions and equality of their variances.

To do these checks we're using the stat_qq functions from the ggplot package and plotting the qq plots for both levels in the same plot:

### Normality plot {#geom_qq}

```{r}
pet_delivery_long %>%
  ggplot(aes(sample = tensile_strength, color = sample)) +
  geom_qq() +
  geom_qq_line() +
  coord_flip() +
  scale_color_viridis_d(begin = 0.1, end = 0.7) +
  labs(title = "PET clothing case study",
       subtitle = "Q-Q plot",
       x = "Residuals",
       y = "Tensile strength [MPa]")
```

We observe that for both levels of treatment the data is adhering to the straight line thus we can assume they follow a normal distribution. Also both lines in the qq plot  have equivalent slopes indicating that the assumption of variances is a reasonable one. These verifications are summary ones. We review in subsequent sessions other deeper verifications of such as the shapiro-wilk normality test.

We're now going to apply the t-test:

```{r}
library(stats)
```

```{r}
t.test(tensile_strength ~ sample, data = pet_delivery_long, var.equal = TRUE)
```

We see that p \< 0.05 thus the means differ significantly. Furthemore the mean difference is estimated with 95% confidence, to be between -0.55 and -0.01 (to be noted that zero is obviously not included in this interval). There is an effect in our treatment that explains the difference in means between the two samples.

## Variances comparison

### F-test {#var.test}

We're now confirming this with a variance test from the stats package.

```{r}
var.test(tensile_strength ~ sample, pet_delivery_long)
```

The test null hypothesis is that the variances are equal. Since the p value is much greater than 0.05 we cannot reject the null hypotheses meaning that we can consider them equal.

The F-test is accurate only for normally distributed data. Any small deviation from normality can cause the F-test to be inaccurate, even with large samples. However, if the data conform well to the normal distribution, then the F-test is usually more powerful than Levene's test.

### Levene test {#levene.test}

This test is assessing the homogeneity of variances (homoscedasticity).

```{r}
library(car)
```

```{r}
leveneTest(tensile_strength ~ sample, data = pet_delivery_long)
```

Pr \> 0.05 thus there is homogeneity of the variances (they do not differ significantly).

Further elaborations on the variance can be found under @minitab_variances.
