
```{r echo=FALSE, message=FALSE, warning=FALSE}
source(here::here("inst/book/setup.R"))
```

# Measurement System Analysis {#MSA}

Validation of a measurement device

## Trueness

<div class="marginnote">

**Case study: juice production plant**

The Quality Control Manager has acquired a fast dry matter content measurement device from the supplier DRX. The rational for the acquisition has been the important reduction of the control time. Now before finally putting it into operation its performance is being assessed and validated.

```{r echo=FALSE, fig.align='center', fig.cap="juice bottling line", out.width="100%"}
knitr::include_graphics("img/juice_bottling_bw.jpg")
```

</div>

In this case study we will look into the assessment of the linearity which is the difference in average bias throughout the measurement range. 

Dry matter content for the company top seller juice_bottling have around  12% dry matter as for example Premium Fresh Apple juice: 12.4 % and Austrian Beetroot: 13.2% and some other specialities may have a higher content up such as Organic Carrot with 16.3%.

It has been decided to start by checking the equipement in the range of 10 to 20% dry matter content.

Lets look into the measurements obtained on the juice bottling process:

```{r}
summary(juice_drymatter)
```

we see raw data for the DRX and Ref equipment allowing us to calculate the difference between the two devices for each measurement:

```{r}
juice_drymatter <- juice_drymatter %>%
  mutate(bias = drymatter_DRX - drymatter_REF, part = as_factor(part))
summary(juice_drymatter$bias)
```

We immediatly see a median bias of -0.2 
Lets explore further.

### Bias plot {#bias_plot}

```{r}
juice_drymatter %>%
  ggplot(aes(x = drymatter_REF, y = bias)) +
  geom_point() +
  geom_smooth(method = "lm", se = T, ) +
  coord_cartesian(
    xlim = c(9,21),
    ylim = c(-.75,0), expand = TRUE) +
  theme_industRial() +
  labs(title = "Dry matter method validation",
       subtitle = "Gage Linearity",
       caption = "Dataset: juice_drymatter233A, Operator: S.Jonathan)")
```

The linear model is well adapted in this case, this by seing the position of the slope close to the averages of each level of the factor. Nevertheless the slope is rather steep showing a clear increase of the bias (in the negative direction) with the increase in dry matter content.

### Bias report {#bias_report}

```{r}
juice_drymatter %>%
  group_by(drymatter_TGT) %>%
  summarise(bias_mean = mean(bias, na.rm = TRUE), 
            bias_median = median(bias, na.rm = TRUE)) %>%
  select(drymatter_TGT, bias_mean, bias_median) %>%
  kable(align = "c", digits = 2)
```

Mean and median bias are very close. A decision now needs to be taken on which systematic offset to apply depending on the operational context. If most products on the line where the device is used a simplified operational procedure with a unique offset of 0.2 can be sufficient.

## Precision

**The tablet compaction process**

Modern pharmaceutical tablet presses reach output volumes of up to 1,700,000 tablets per hour. These huge volumes require frequent in-process quality control for the tablet weight, thickness and hardness.

In our case study we're going to measurement the precision of the measurement method used to determine the thickness of the tablet.

<div class="marginnote">

```{r echo=FALSE, fig.align='center', fig.cap="Tablet thickness micrometer", out.width="100%"}
knitr::include_graphics("img/tablet_micrometer.png")
# sources: 
# https://en.wikipedia.org/wiki/Tablet_(pharmacy)#Manufacture_of_the_tablets
# https://www.ischi.com/ipc-line/uts-ip-lr-easy-to-clean/
```

</div>

According to the ISO 5725 the Precision of a measurement method is the combination of the Reproductibility & Reproducibility.

**Data loading**

We use here the data from the tablet thickness method validation:

```{r}
str(tablet_thickness)
```

We see that quite an extensive variaty of parameters was collected here including room conditions. We are mostly interested in the tablet size, thickness and operator who has performed the measurement. As these parameters are coded as characters we are going to convert them to factors:

```{r}
tablet_thickness <- tablet_thickness %>%
  clean_names() %>%
  mutate(across(c(size, tablet, operator), as_factor))
```

We want to establish an independed r&R by specification size (S, M or L) and so we first filter only for the first size the L.

```{r}
tablet_L <- tablet_thickness %>%
  filter(size == "L")
```

Below we're doing the same analysis with the ss.rr function from the Six Sigma package. As the function allows to input the limits we're also providing in the function arguments the current upper and lower limit of the specification.

tablet L 1'800mm3 +/- 25mm3 (18.0ml +/- 0.25ml)

### Gage r&R {#gageRnR}

```{r}
library(SixSigma)
```

```{r, fig.dim = c(8, 10)}
tablet_L_rr <- ss.rr(
  data = tablet_L, 
  var = thickness_micron, 
  part = tablet, 
  appr = operator, 
  alphaLim = 1,
  errorTerm = "repeatability", # very important otherwise F test not identical to base aov
  main = "Micrometer FTR600\nr&R for tablet thickness",
  sub = "Tablet L",
  lsl = 1775,
  usl = 1825
)
```

We can observe that the SixSigma package recreates exactly the same anova table, just calling Repeatability to the Residuals and adding an additional line with the total degrees of freedom and the total sum of squares. 

Note that the argument alphaLim has been set to 1 to avoid suppressing the interaction which is in this case non significative.

### Gage acceptance {#gage_acceptance}

#### Variance criteria

To evaluate your process variation, compare the Total Gage R&R contribution in the %Contrib column with the values in the list below:

* Less than 1%: the measurement system is acceptable

* Between 1% and 9%: the measurement system is acceptable depending on the application, the cost of the measurement device, cost of repair, or other factors

* Greater than 9%: the measurement system is not acceptable and should be improved.

#### Standard deviation criteria

The study variation table is established by calculating the square root of each variance (the standard deviation) and by multiplying it by 6 (the six sigma) and then again by comparing each variation with the total variation. Standard deviations are usualy more speaking to the industry professionals. This table also provides a comparison with the specification.

According to the guidelines from the @AIAG2010, if your system variation is less than 10% of the process variation, then it is acceptable.

To evaluate your process variation, compare the Total Gage R&R contribution in the %StudyVar column with the values in the list below:

* Less than 10%: the measurement system is acceptable

* Between 10% and 30%: the measurement system is acceptable depending on the application, the cost of the measurement device, cost of repair, or other factors

* Greater that 30%: the measurement system is not acceptable and should be improved.

If the p-value for the operator and part interaction is 0.05 or higher, the system removes the interaction because it is not significant and generates a second ANOVA table without the interaction.

The AIAG also states that the number of distinct categories into which the measurement system divides process output should be greater or equal to 5.

The part to part variation is high which is what is expected in a study like this.

In our specific example we observe that the device cannot be accepted as the Study variation for the Total Gage r&R is 38.46% thus much higher than 30%. Furhtermore the number of distinc categories is only of 3. 

Finaly to be noted that the total variation rather low when compared with the specification.

In a nutshell two questions are answered:

* can the method be used to assess process performance: no the measurement system variation equals 38.4% of the process variation,

* can the method be used to sort good parts from bad: yes but can be improved, the measurement system variation equals 15.3% of the tolerance.

#### Negative variance

Two important limitations exist in the current approach:

1) when the operators reproducibility is negative it is converted to zero.

[@Montgomery2012] in page 557 adresses this case in the following way:

*Notice that the estimate of one of the variance components,is negative. This is certainly not reasonable because by definition variances are nonnegative. Unfortunately, negative estimates of variance components can result when we use the analysis of variance method of estimation (this is considered one of its drawbacks). We can deal with this negative result in a variety of ways:*

*1) one possibility is to assume that the negative estimate means that the variance component is really zero and just set it to zero, leaving the other nonnegative estimates unchanged.*

*2) Another approach is to estimate the variance components with a method that assures nonnegative estimates (this can be done with the maximum likelihood approach).*

*3) Finally, we could note that the P-value for the interaction term ... is very large, take this as evidence that really is zero and that there is no interaction effect, and then fit a reduced model of the form that does not include the interaction term. This is a relatively easy approach and one that often works nearly as well as more sophisticated methods.*

This final approach is also what the SixSigma package creators have foreseen and if we leave the argument alphaLim empty the non significant terms will be suppressed from the model, the Anova recalculated and the remaining tables updated accordingly. This can be finetuned with the argument alphaLim. Usually we consider a p value of 0.05 but we recommend to start with higher values such as 0.1 or 0.2 to avoid suppressing too quickly the factor which would result in a transfer of their variability into the repeatability.

```{r, fig.dim = c(8, 10)}
tablet_L_rr2 <- ss.rr(
  data = tablet_L, 
  var = thickness_micron, 
  part = tablet, 
  appr = operator, 
  alphaLim = 0.2, # instead of 0.05 it is recommended to start higher
  errorTerm = "repeatability",
  main = "Micrometer FTR600\nr&R for tablet thickness",
  sub = "Tablet L",
  lsl = 1775,
  usl = 1825
)
```

In our case when comparing the total gage r&R with and without the interaction we see it changing from 38.46% to 38.38%.

## Uncertainty {#uncertainty}

A final step in the validation of our measurement device is now the calculation of the total measurement uncertainty. 

In some reports the terminology uncertainty is prefered instead of gage r&R.
In this case the formula usually used to evaluate the measurement uncertainty is:

$$
u^2=u_{repeat.}^2+ u_{reprod.}^2+ u_{cal.}^2
$$

where the repeatability and reproducibility members can be obtained from the variances calculated in the r&R study

$$
u_{repeat}^2 = σ_{repeat}^2\\
u_{reprod}^2 = σ_{reprod}^2
$$
These variance components can be directly obtained from the object generated by the function ss.rr of the {SixSigma} package. If we name our variable $σ_{repeat}^2$ as repeat_var in R we have:

```{r}
repeat_var <- tablet_L_rr$varComp[2,1]
repeat_var
```

and for the reproducibility we have:

```{r}
reprod_var <- tablet_L_rr$varComp[3,1]
reprod_var
```

The equipment manual mentions an accuracy of 0.001 mm. If we take this as the calibration uncertainty expressed as a standard deviation, this means we have:

$$
u_{cal} = 0.001 mm \Leftrightarrow 1 \mu m\\
u_{cal}^2 = 1^2 = 1
$$
that we can assign in R to the variable calibration_var. 
```{r}
calibration_var <- 1
```


We thus we have a uncertainty of:

```{r}
u <- sqrt(reprod_var + repeat_var + calibration_var)
u
```

Finally what is usually reported is the expanded uncertainty corresponding to 2 standard deviations. To be recalled that $\pm$ 2 std corresponds to 95% of the values when a repeative measurement is done. In this case we have $U = 2*u$:

```{r}
U <- 2 * u
U
```

For a specific measurement of say 1'800 $\mu m$ we then say: the tablet thickness is 1'800 $\mu m$ $\pm$ `r round(U,1)` $\mu m$, at the 95 percent confidence level. Or written in short:

1'800 $\mu m$ $\pm$ `r round(U,1)` $\mu m$, at a level of confidence of 95%

Knowing that the specification is [1'775; 1'825] $\mu$m we have a specification range of 500. The expanded uncertainty corresponds to `r round(2*U/50*100,2)` %. This is another way of looking into the ratio between method variation and specification. This {SixSigma} package gave a similar result of 15.37%. To be noted that the calculation in by the package corresponds to 3 standard deviations and does not comprise the supplier calibration.

For further reading on the topic we recommend the booklet from @Bell2001.