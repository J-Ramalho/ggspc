
```{r echo=FALSE, message=FALSE, warning=FALSE}
source(here::here("inst/book/setup.R"))
```

# Measurement System Analysis {#MSA}

Analyzing and validating measurement methods and tools is the base for ensuring the quality of manufacturing products. For most commercial products it goes beyond simply satisfying consumer expectations and has regulatory and legal implications. Using measurement tools in industrial setups for high volume production goes naturally beyond buying and installing an equipment. It requires clear operating procedures, trained operators and tested devices for the specific range applications and products. 

There are many different normalizing bodies in the metrology domain with different approaches and terminology. The cases in this section follow a simplified step by step approach aiming at giving an overview of how data treatment can be done with R.

The first case treats the calibration of a recently acquired measurement device by comparing it to a reference device. It provides statistical analysis of the bias of the method compared with the reference for the full measurement range. The following case deals with the estimation of the method precision, namely the measurement repeatability and reproducibility under regular utilization conditions. It provides examples on acceptance criteria typical in industrial context. The final case study presents calculation of the method uncertainty, a more comprehensive indicator taking into account the calculations done in the previous cases.

## Calibration

<div class="marginnote">

<b class="highlight">Case study: juice production plant</b>

The Quality Assurance Head has acquired a fast dry matter content measurement device from the supplier DRX. The rational for the acquisition has been the important reduction of the control time. Before it enters operation its performance is being assessed and validated.

```{r img-juice, echo=FALSE, fig.align='center', fig.cap="juice bottling line", out.width="100%"}
knitr::include_graphics("img/juice_bottling_bw.jpg")
```

</div>

A first step after a measurement equipment acquisition is the assessment of the response over the entire measurement range. In particular it is important to verify its linearity and variability and determine the average bias throughout the measurement range. 

In a <b class="highlight">juice production plant</b> the dry matter content for the top seller is around 13% dry matter content. Typical specifications are the Premium fresh apple juice with 12.4 % and the Austrian beetroot juice with 13.2%. Some other specialties may have a higher content up such as the Organic carrot that has 16.3%. After consulting with the Manufacturing Team Leader, the Quality Assurance Head selects checking the equipment in the range of 10 to 20% dry matter content. For the calibration assessment samples are produced at target values set at round numbers (10%, 15% and so on). This data is captured in the `juice_drymatter` dataset of which we're checki

```{r code-juicesummary}
juice_drymatter %>%
  head(5) %>%
  kable(
    align = "c",
    caption = "juice dry matter data"
        )
```

We see in this raw dataset that it contains the same samples dry matter content measured twice. First with the with the new equipment (DRX) and then with the reference equipment (Ref). The reference equipment is considered as such because it has been validated and accepted by the head quarters quality department. The difference between the two devices for each measurement is calculated below and allocated to a new variable with the name bias.

```{r code-juicebias}
juice_drymatter <- juice_drymatter %>%
  mutate(bias = drymatter_DRX - drymatter_REF, part = as_factor(part))
```

A first look at the bias with the `skim()` function from `{skimr}` gives already an indication that the bias is not constant along the measurement range.

<div class="marginnote">
See [{skimr}](#skimr) for more details on this R package, an alternative to base::summary()
</div>

```{r load-skimr}
library(skimr)
```

```{r code-juiceskim}
skim(juice_drymatter$bias) %>%
  yank("numeric")
```

Such results are not encouraging because a non regular bias along the range may require specific correction for different product which may be not practical and prone to error. Often this requires to dig into detail to understand the causes of the bias and determine if they are related with the physical phenomena and if there are clear controllable causes. Ultimately this could result is narrowing the measurement range and validating a specific device and method for a specific product specification target. For the Quality Assurance Manager it is too early to draw conclusions and he establishes a more detailed plot with `{ggplot2}` to better visualize the data.

### Bias plot {#bias_plot}

```{r fig-juicebiasplot, fig.align='center', fig.cap="bias plot example"}
juice_drymatter %>%
  ggplot(aes(x = drymatter_REF, y = bias)) +
  geom_point() +
  geom_smooth(method = "lm", se = T, ) +
  coord_cartesian(
    xlim = c(9,21),
    ylim = c(-.75,0), expand = TRUE) +
  theme_industRial() +
  labs(title = "Dry matter method validation",
       subtitle = "Gage Linearity",
       caption = "Dataset: juice_drymatter233A, Operator: S.Jonathan)")
```

This type of plot is usually called *bias plot* and provides a view of how the difference between the measurements obtained with the new device and the reference device compare allong the measuremen range. In the plot generated an additional regression line has been introduced with `geom_smooth` from `{ggplot2}`. There are several ways to assess the linearity. In this case we're going to remain at a visual check only leaving to the Design of Experiments case study a more thourough verification.

The linear model appears as well adapted in this case. The first check is the observation that regression line passes close to the averages of each level of the dry matter factor. Nevertheless the slope is rather steep showing a clear increase of the bias (in the negative direction) with the increase in dry matter content.

### Bias report {#bias_report}

Using well known `{dplyr}` function the plot is complemented with statistics of the bias for each level of dry matter target: mean, median, standard deviation. A good practice that took some time to adopt but now is well anchored is to always present the sample size which speaks for the relevance of the statistical indicators.

```{r tbl-juicebias}
juice_drymatter %>%
  group_by(drymatter_TGT) %>%
  summarise(bias_mean = mean(bias, na.rm = TRUE), 
            bias_median = median(bias, na.rm = TRUE),
            bias_sd = sd(bias, na.rm = TRUE), 
            bias_n = n()) %>%
  # select(drymatter_TGT, bias_mean, bias_median) %>%
  kable(align = "c", digits = 2)
```

Mean and median bias are very close which indicates that the data is equally distributed around the mean The standard deviation is also very similar from level to level indicating that the measurement variability is not depending on the range of measurement. A decision now needs to be taken on which systematic offset to apply depending on the operational context. As mentioned most commercial products on the production line where the device is used have a target specification around 13% therefore the Quality Assurance Head decides together with Manufacturing Team Leader to put in the operating procedure of the device a unique offset of 0.3 g.

## Precision

<div class="marginnote">

<b class="highlight">Case study: tablet compaction process</b>

Modern pharmaceutical tablet presses reach output volumes of up to 1,700,000 tablets per hour. These huge volumes require frequent in-process quality control for the tablet weight, thickness and hardness.

```{r img-tablet, echo=FALSE, fig.align='center', fig.cap="Tablet thickness micrometer", out.width="100%"}
knitr::include_graphics("img/tablet_micrometer.png")
# sources: 
# https://en.wikipedia.org/wiki/Tablet_(pharmacy)#Manufacture_of_the_tablets
# https://www.ischi.com/ipc-line/uts-ip-lr-easy-to-clean/
```

</div>

Pharmaceutical production setups combine uniquely extreme high volumes with stringent quality demands. In a pharmaceutical <b class="highlight">tablet compaction process</b> the quality measurement system requires the Production Operator to sample tablets on a regular basis and log the thickness in a spreadsheet on the line. Although many companies have now inline automatic measurement devices providing automatic data collection to a central database it is not uncommon to see hand held devices and manual log of measurements in spreadsheets. In an age of machine learning and sophisticated predictive tools this may seem awkward but it is common to see coexisting old and new approaches on the shop floor.

A recurring check of measurement devices is the famous gage r&R. r&R stands for reproducibility and Reproductibility which combined give the instrument precision, according to the ISO 5725.

In fact besides thickness, the quality measurement system requires the operator to collect quite an large variety of parameters including room conditions. Elaborating on this a Quality Engineer has prepared a specific file for the gage r&R that also included the replicate number. As it is common practice he asked the measurements to be done by several operators. This data has been loaded into R and is available in the dataset `tablet_thickness` and an extract is presented here in raw:

```{r tbl-tabletthickness}
tablet_thickness %>%
  head(3) %>%
  kable(
    align = "c",
    caption = "tablet thickness gage r&R data"
  )
```

It is an excellent practice to look at raw data because it gives an immediate perception of general aspects such as the number of variables, their levels and their datatypes. Although this is irreplaceable it is possible to go further and `skim()` provides an excellent complement and summary. Below we see that the test requested by the Quality Engineer has required 675 measurements on 11 different variables by 3 different operators. We can see room conditions are stable, rather normally distributed and having small standard deviations and we can even see that thickness appears with 3 groups which seems related with the 3 sizes noted in the Size column.

```{r tbl-tabletskim}
skim(tablet_thickness) 
```

The initial idea of the Quality Engineer was to establish a separate gage r&R by tablet size. There is sometimes debate if in the study several different specification should be combined or not. In the last quality weekly meeting this was reason for lively discussions with various logical arguments from the Production Leader and the Engineering Manager. They ended up accepting the proposal of a separate gage per size on the logic that it is important to compare the measurement method variability not only with the process variability but also with the specification itself.

Data in excel files to have most of the time human readable formats and the files being open they usually end up with long variable names. Unlike the classical `read.csv()` function from the base R the `read_csv()` function from `{readr}` is not converting character variables to factors. This is a good behavior in our view because it allows for better control and awareness of what is happening. In this case the Quality Engineer is acquainted to the `{tidyverse}` and is now making the conversion specifically on the desired variables size, tablet and operator. He also makes the filtering for the size L for which he will do the first r&R study.

```{r code-tabletfactor}
tablet_thickness <- tablet_thickness %>%
  clean_names() %>%
  mutate(across(c(size, tablet, operator), as_factor))

tablet_L <- tablet_thickness %>%
  filter(size == "L")
```

Now that the dataset is clean and ready he moves forward with the `ss.rr()` function from the `{SixSigma}` package. As the function allows to input the limits he also provides in the arguments the current upper and lower limit of the specification, in this case of 1'800 $\mu m$ +/- 25 $\mu m$ for tablet L. Note that he sets the `alphaLim` argument to 1 in this first assessment to be able to see all the model terms including non significant one. In subsequent analysis this can be set to 0.05 the usual significance threshold.

### Gage r&R {#gageRnR}

```{r load-SixSigma}
library(SixSigma)
```

```{r fig-tableRnR, fig.dim = c(8, 10), fig.align='center', fig.cap="r&R example report"}
tablet_L_rr <- ss.rr(
  data = tablet_L, 
  var = thickness_micron, 
  part = tablet, 
  appr = operator, 
  alphaLim = 1,
  errorTerm = "repeatability", # very important otherwise F test not identical to base aov
  main = "Micrometer FTR600\nr&R for tablet thickness",
  sub = "Tablet L",
  lsl = 1775,
  usl = 1825
)
```

### Gage acceptance {#gage_acceptance}

#### Variance criteria

To evaluate your process variation, compare the Total Gage R&R contribution in the %Contrib column with the values in the list below:

* Less than 1%: the measurement system is acceptable

* Between 1% and 9%: the measurement system is acceptable depending on the application, the cost of the measurement device, cost of repair, or other factors

* Greater than 9%: the measurement system is not acceptable and should be improved.

#### Standard deviation criteria

The study variation table is established by calculating the square root of each variance (the standard deviation) and by multiplying it by 6 (the six sigma) and then again by comparing each variation with the total variation. Standard deviations are usualy more speaking to the industry professionals. This table also provides a comparison with the specification.

According to the guidelines from the @AIAG2010, if your system variation is less than 10% of the process variation, then it is acceptable.

To evaluate your process variation, compare the Total Gage R&R contribution in the %StudyVar column with the values in the list below:

* Less than 10%: the measurement system is acceptable

* Between 10% and 30%: the measurement system is acceptable depending on the application, the cost of the measurement device, cost of repair, or other factors

* Greater that 30%: the measurement system is not acceptable and should be improved.

If the p-value for the operator and part interaction is 0.05 or higher, the system removes the interaction because it is not significant and generates a second ANOVA table without the interaction.

The AIAG also states that the number of distinct categories into which the measurement system divides process output should be greater or equal to 5.

The part to part variation is high which is what is expected in a study like this.

In our specific example we observe that the device cannot be accepted as the Study variation for the Total Gage r&R is 38.46% thus much higher than 30%. Furhtermore the number of distinc categories is only of 3. 

Finaly to be noted that the total variation rather low when compared with the specification.

In a nutshell two questions are answered:

* can the method be used to assess process performance: no the measurement system variation equals 38.4% of the process variation,

* can the method be used to sort good parts from bad: yes but can be improved, the measurement system variation equals 15.3% of the tolerance.

#### Negative variance

Two important limitations exist in the current approach:

1) when the operators reproducibility is negative it is converted to zero.

[@Montgomery2012] in page 557 adresses this case in the following way:

*Notice that the estimate of one of the variance components,is negative. This is certainly not reasonable because by definition variances are nonnegative. Unfortunately, negative estimates of variance components can result when we use the analysis of variance method of estimation (this is considered one of its drawbacks). We can deal with this negative result in a variety of ways:*

*1) one possibility is to assume that the negative estimate means that the variance component is really zero and just set it to zero, leaving the other nonnegative estimates unchanged.*

*2) Another approach is to estimate the variance components with a method that assures nonnegative estimates (this can be done with the maximum likelihood approach).*

*3) Finally, we could note that the P-value for the interaction term ... is very large, take this as evidence that really is zero and that there is no interaction effect, and then fit a reduced model of the form that does not include the interaction term. This is a relatively easy approach and one that often works nearly as well as more sophisticated methods.*

This final approach is also what the SixSigma package creators have foreseen and if we leave the argument alphaLim empty the non significant terms will be suppressed from the model, the Anova recalculated and the remaining tables updated accordingly. This can be finetuned with the argument alphaLim. Usually we consider a p value of 0.05 but we recommend to start with higher values such as 0.1 or 0.2 to avoid suppressing too quickly the factor which would result in a transfer of their variability into the repeatability.

```{r, fig.dim = c(8, 10)}
tablet_L_rr2 <- ss.rr(
  data = tablet_L, 
  var = thickness_micron, 
  part = tablet, 
  appr = operator, 
  alphaLim = 0.2, # instead of 0.05 it is recommended to start higher
  errorTerm = "repeatability",
  main = "Micrometer FTR600\nr&R for tablet thickness",
  sub = "Tablet L",
  lsl = 1775,
  usl = 1825
)
```

In our case when comparing the total gage r&R with and without the interaction we see it changing from 38.46% to 38.38%.

## Uncertainty {#uncertainty}

A final step in the validation of our measurement device is now the calculation of the total measurement uncertainty. 

In some reports the terminology uncertainty is prefered instead of gage r&R.
In this case the formula usually used to evaluate the measurement uncertainty is:

$$
u^2=u_{repeat.}^2+ u_{reprod.}^2+ u_{cal.}^2
$$

where the repeatability and reproducibility members can be obtained from the variances calculated in the r&R study

$$
u_{repeat}^2 = σ_{repeat}^2\\
u_{reprod}^2 = σ_{reprod}^2
$$
These variance components can be directly obtained from the object generated by the function ss.rr of the {SixSigma} package. If we name our variable $σ_{repeat}^2$ as repeat_var in R we have:

```{r}
repeat_var <- tablet_L_rr$varComp[2,1]
repeat_var
```

and for the reproducibility we have:

```{r}
reprod_var <- tablet_L_rr$varComp[3,1]
reprod_var
```

The equipment manual mentions an accuracy of 0.001 mm. If we take this as the calibration uncertainty expressed as a standard deviation, this means we have:

$$
u_{cal} = 0.001 mm \Leftrightarrow 1 \mu m\\
u_{cal}^2 = 1^2 = 1
$$
that we can assign in R to the variable calibration_var. 
```{r}
calibration_var <- 1
```


We thus we have a uncertainty of:

```{r}
u <- sqrt(reprod_var + repeat_var + calibration_var)
u
```

Finally what is usually reported is the expanded uncertainty corresponding to 2 standard deviations. To be recalled that $\pm$ 2 std corresponds to 95% of the values when a repeative measurement is done. In this case we have $U = 2*u$:

```{r}
U <- 2 * u
U
```

For a specific measurement of say 1'800 $\mu m$ we then say: the tablet thickness is 1'800 $\mu m$ $\pm$ `r round(U,1)` $\mu m$, at the 95 percent confidence level. Or written in short:

1'800 $\mu m$ $\pm$ `r round(U,1)` $\mu m$, at a level of confidence of 95%

Knowing that the specification is [1'775; 1'825] $\mu$m we have a specification range of 500. The expanded uncertainty corresponds to `r round(2*U/50*100,2)` %. This is another way of looking into the ratio between method variation and specification. This {SixSigma} package gave a similar result of 15.37%. To be noted that the calculation in by the package corresponds to 3 standard deviations and does not comprise the supplier calibration.

For further reading on the topic we recommend the booklet from @Bell2001.